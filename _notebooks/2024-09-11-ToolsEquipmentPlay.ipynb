{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "comments: true\n",
    "layout: post\n",
    "title: Tools & Equipment Play Hacks\n",
    "courses: { compsci: {week: 2} }\n",
    "type: hacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies to local, if not pre-installed:\n",
    "```pip install wikipedia-api emoji```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Wikipedia articles:\n",
      "- music: https://en.wikipedia.org/wiki/Music\n",
      "- car: https://en.wikipedia.org/wiki/Car\n",
      "- history: https://en.wikipedia.org/wiki/History\n",
      "- river: https://en.wikipedia.org/wiki/River\n",
      "- sun: https://en.wikipedia.org/wiki/Sun\n",
      "\n",
      "Most common word: music\n",
      "Word in emoji form: 🅼🆄🆂🅸🅲\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize Wikipedia API, needs a valid User-Agent\n",
    "user_agent = 'MyWikipediaScript/1.0 (https://example.com; myemail@example.com)'  # Replace with your details\n",
    "wiki = wikipediaapi.Wikipedia('en', headers={'User-Agent': user_agent})\n",
    "\n",
    "# Function to clean/extract words from text\n",
    "def extract_words(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove non-alphabet characters\n",
    "    words = text.split()  # Split text into words\n",
    "    return words\n",
    "\n",
    "# Generate random article titles from a list of common ones\n",
    "def get_random_titles():\n",
    "    common_words = [\n",
    "        'apple', 'dog', 'music', 'computer', 'ocean', 'earth', 'history', 'science', \n",
    "        'car', 'mountain', 'sun', 'moon', 'technology', 'book', 'river', 'forest'\n",
    "    ]\n",
    "    random_titles = random.sample(common_words, 5)  # Pick 5 random titles from the list\n",
    "    return random_titles\n",
    "\n",
    "# Get 5 Wikipedia articles by random titles and scan for the most common word\n",
    "def get_common_word_from_random_articles():\n",
    "    titles = get_random_titles()\n",
    "    articles = []\n",
    "    \n",
    "    print(\"Selected Wikipedia articles:\")\n",
    "    \n",
    "    for title in titles:\n",
    "        page = wiki.page(title)\n",
    "        \n",
    "        # If the article exists, get the text content\n",
    "        if page.exists():\n",
    "            print(f\"- {title}: {page.fullurl}\")\n",
    "            articles.append(page.text)\n",
    "        else:\n",
    "            print(f\"- {title}: (Article does not exist)\")\n",
    "    \n",
    "    if not articles:\n",
    "        return None\n",
    "\n",
    "    # Combine text from all articles\n",
    "    combined_text = ' '.join(articles)\n",
    "    words = extract_words(combined_text)\n",
    "    \n",
    "    # Count the most common word\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Skip common English words and find the most frequent\n",
    "    common_words = [word for word, _ in word_counts.most_common() if len(word) > 3]\n",
    "    \n",
    "    if common_words:\n",
    "        most_common_word = common_words[0]\n",
    "        return most_common_word\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Convert word to emoji format with the specified emojis\n",
    "def word_to_emoji(word):\n",
    "    letter_emoji_map = {\n",
    "        'a': '🅰', 'b': '🅱', 'c': '🅲', 'd': '🅳', 'e': '🅴', 'f': '🅵',\n",
    "        'g': '🅶', 'h': '🅷', 'i': '🅸', 'j': '🅹', 'k': '🅺', 'l': '🅻',\n",
    "        'm': '🅼', 'n': '🅽', 'o': '🅾', 'p': '🅿', 'q': '🆀', 'r': '🆁',\n",
    "        's': '🆂', 't': '🆃', 'u': '🆄', 'v': '🆅', 'w': '🆆', 'x': '🆇',\n",
    "        'y': '🆈', 'z': '🆉'\n",
    "    }\n",
    "    return ''.join([letter_emoji_map.get(char, char) for char in word])\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    most_common_word = get_common_word_from_random_articles()\n",
    "    \n",
    "    if most_common_word:\n",
    "        print(f\"\\nMost common word: {most_common_word}\")\n",
    "        emoji_word = word_to_emoji(most_common_word)\n",
    "        print(f\"Word in emoji form: {emoji_word}\")\n",
    "    else:\n",
    "        print(\"No common word found or articles do not exist\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style> \n",
    "@import url('https://fonts.googleapis.com/css2?family=Roboto');\n",
    "h1{ text-align: center; font-size: 50px; color: #0352fc; font-family: 'Roboto', serif;}\n",
    "h2{ text-align: left; font-size: 18px; color: #0352fc;}\n",
    "body{ text-align: left; font-size: 15px; font-family: 'Roboto', serif; background: black; }\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
